{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',214)\n",
    "pd.set_option('display.max_rows',214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    df = pd.read_csv('Glass.csv')\n",
    "    # df.set_index('ID', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of instances among classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts(data):\n",
    "    class_count  = data['Class'].value_counts()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=class_count.index, y=class_count.values, alpha=0.8)\n",
    "    plt.title('Glass classes counts')\n",
    "    plt.ylabel('Number of instances', fontsize=12)\n",
    "    plt.xlabel('Class', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "show_counts(df)\n",
    "# we can see that first two classes contain most (over 67%) of the observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=df.columns\n",
    "col_names_glass = [x for x in list(df) if x not in ['ID','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plots(data):    \n",
    "    sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "    plt.subplots(figsize = (20,15))\n",
    "    for n in col_names_glass:\n",
    "        plt.subplot(3,3,(col_names_glass.index(n)+1))\n",
    "        sns.boxplot(x='Class', y=n, data=data)\n",
    "box_plots(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.columns.difference(['ID', 'Class'])].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x = df[col_names_glass].values\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=col_names_glass, index = df.index)\n",
    "    df[col_names_glass] = df_temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "    return data[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "\n",
    "# For each column, first it computes the Z-score of each value in the column, relative to the column mean and standard deviation.\n",
    "# Then is takes the absolute of Z-score because the direction does not matter, only if it is below the threshold.\n",
    "# all(axis=1) ensures that for each row, all column satisfy the constraint.\n",
    "# Finally, result of this condition is used to index the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(data):\n",
    "    scaled = scale_data(data)             # scaling data\n",
    "    no_outliers = remove_outliers(scaled) # removing outliers\n",
    "    return no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = wrangle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_outliers(old_data, new_data):\n",
    "    l=[]\n",
    "    for x in range(0,215):\n",
    "        if x not in new_data['ID']:\n",
    "            l.append(x)\n",
    "    return old_data[old_data['ID'].isin(l)]\n",
    "\n",
    "show_outliers(df, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[:, new_df.columns.difference(['ID', 'Class'])].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def kdeplots(data):\n",
    "#    for col in col_names_glass:\n",
    "#        sns.kdeplot(data[col], shade=True, color=\"r\")\n",
    "#        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdeplots(data):    \n",
    "    plt.subplots(figsize = (20,15))\n",
    "    plt.subplot(3,3,1)\n",
    "    sns.kdeplot(data['Ri'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,2)\n",
    "    sns.kdeplot(data['Na'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,3)\n",
    "    sns.kdeplot(data['Mg'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,4)\n",
    "    sns.kdeplot(data['Al'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,5)\n",
    "    sns.kdeplot(data['Si'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,6)\n",
    "    sns.kdeplot(data['K'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,7)\n",
    "    sns.kdeplot(data['Ca'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,8)\n",
    "    sns.kdeplot(data['Ba'], shade=True, color=\"r\")\n",
    "    plt.subplot(3,3,9)\n",
    "    sns.kdeplot(data['Fe'], shade=True, color=\"r\")\n",
    "\n",
    "kdeplots(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(new_df.loc[:, df.columns.difference(['ID'])].corr(),annot=True,cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plots(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all histograms of each features after scaling\n",
    "\n",
    "def histograms(data):\n",
    "    data[col_names_glass].hist(bins = 50, figsize = (25,25), xlabelsize = 1, ylabelsize = 1)\n",
    "    plt.show()\n",
    "    \n",
    "#histograms(df)\n",
    "histograms(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plots(data):\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.3)\n",
    "    plt.subplots(figsize = (35,30))\n",
    "    for n in ['Ri','Na','Mg','Al','Si','Ca']:\n",
    "        plt.subplot(3,3,(['Ri','Na','Mg','Al','Si','Ca'].index(n)+1))\n",
    "        sns.kdeplot(data[n][data.Class == 1], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 2], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 3], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 4], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 5], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 6], shade = True)\n",
    "        sns.kdeplot(data[n][data.Class  == 7], shade = True)\n",
    "        plt.title(f'{n} distribution among classes')\n",
    "        plt.legend(['Class 1', 'Class 2', 'Class 3','Class 5', 'Class 6', 'Class 7'])\n",
    "        \n",
    "    plt.subplot(3,3,7)\n",
    "    sns.kdeplot(data['K'][data.Class == 1], shade = True)\n",
    "    sns.kdeplot(data['K'][data.Class == 2], shade = True)\n",
    "    sns.kdeplot(data['K'][data.Class == 3], shade = True)\n",
    "    sns.kdeplot(data['K'][data.Class == 5], shade = True)\n",
    "    sns.kdeplot(data['K'][data.Class == 7], shade = True)\n",
    "    plt.title('K distribution among classes')\n",
    "    plt.legend(['Class 1', 'Class 2', 'Class 3','Class 5', 'Class 7'])\n",
    "    \n",
    "        \n",
    "    plt.subplot(3,3,8)\n",
    "    sns.kdeplot(data['Ba'][data.Class == 1], shade = True)\n",
    "    sns.kdeplot(data['Ba'][data.Class == 2], shade = True)\n",
    "    sns.kdeplot(data['Ba'][data.Class == 3], shade = True)\n",
    "    sns.kdeplot(data['Ba'][data.Class == 7], shade = True)\n",
    "    plt.title('Ba distribution among classes')\n",
    "    plt.legend(['Class 1', 'Class 2', 'Class 3','Class 7'])\n",
    "    \n",
    "    plt.subplot(3,3,9)\n",
    "    sns.kdeplot(data['Fe'][data.Class == 1], shade = True)\n",
    "    sns.kdeplot(data['Fe'][data.Class == 2], shade = True)\n",
    "    sns.kdeplot(data['Fe'][data.Class == 3], shade = True)\n",
    "    sns.kdeplot(data['Fe'][data.Class == 5], shade = True)\n",
    "    sns.kdeplot(data['Fe'][data.Class == 7], shade = True)\n",
    "    plt.title('Fe distribution among classes')\n",
    "    plt.legend(['Class 1', 'Class 2', 'Class 3','Class 5', 'Class 7'])\n",
    "    \n",
    "density_plots(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[col_names_glass] \n",
    "y = new_df['Class'] \n",
    "seed = 7\n",
    "test_size = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size , random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state = seed)\n",
    "pca.fit(X_train)\n",
    "v = pca.explained_variance_ratio_\n",
    "c = np.cumsum(v)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylabel('Variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.xticks(np.arange(1,len(v)+1,1))\n",
    "plt.bar(range(1,len(c)+1), v, align= 'center', label= 'individual variance', alpha = 0.5)\n",
    "plt.step(range(1,len(c)+1), c, where = 'mid' , label= 'cumulative variance', color= 'orange')\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm = svm.SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "acc1 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse1 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse1 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm1 = confusion_matrix(y_pred,y_test)\n",
    "x_axis_labels = [1,2,3,5,6,7]\n",
    "y_axis_labels = [1,2,3,5,6,7]\n",
    "\n",
    "sns.heatmap(cm1, annot=True, cmap=\"Greens\", cbar=False, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "trees = tree.DecisionTreeClassifier()\n",
    "trees.fit(X_train, y_train)\n",
    "y_pred = trees.predict(X_test)\n",
    "acc2 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse2 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse2 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm2 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm2, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "forest = ensemble.RandomForestClassifier(max_depth = 3, min_samples_split=2, n_estimators = 50, random_state = seed)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "acc3 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse3 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse3 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cm3 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm3, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgbMod = XGBClassifier(max_depth = 3, n_estimators = 100, learning_rate = 0.05, random_state = seed)\n",
    "xgbMod.fit(X_train,y_train)\n",
    "y_pred = xgbMod.predict(X_test)\n",
    "acc4 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse4 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse4 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cm4 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm4, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc5 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse5 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse5 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cm5 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm5, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lgstc = linear_model.LogisticRegression(random_state=seed, solver=\"lbfgs\", multi_class=\"multinomial\",class_weight='balanced').fit(X_train, y_train)\n",
    "lgstc.score(X_test, y_test)\n",
    "lgstc = lgstc.fit(X_train, y_train)\n",
    "y_pred = lgstc.predict(X_test)\n",
    "acc6 = metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "mse6 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse6 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cm6 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm6, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(columns=['Algorithm','Accuracy','MSE'])\n",
    "names=['SVM','Decision Tree','Random Forest','XGBoost','KNN','Logistic Regression']\n",
    "for x in range(0,len(names)):\n",
    "    results.loc[x] = [names[x],vars()['acc' + str(x+1)], vars()['mse' + str(x+1)]]\n",
    "results.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "results.set_index('Algorithm', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling&Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors': np.arange(1, 30)}\n",
    "knn2 = GridSearchCV(knn, parameters_knn, cv=4)\n",
    "knn2.fit(X_train, y_train)\n",
    "knn_best = knn2.best_estimator_\n",
    "print(knn2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc23 = metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "mse23 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse23 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm23 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm23, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators' : [50, 100, 150, 200, 250, 275, 300, 350, 400],\n",
    "'min_samples_split': np.arange(1, 5),\n",
    "'max_depth': np.arange(1, 10)}\n",
    "\n",
    "forest_t = GridSearchCV(forest, parameters, n_jobs=-1, verbose=2, refit = \"accuracy_score\")\n",
    "forest_t.fit(X_train, y_train)\n",
    "\n",
    "best_pars = forest_t.best_params_\n",
    "best_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=best_pars['n_estimators']\n",
    "b=best_pars['max_depth']\n",
    "c=best_pars['min_samples_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ensemble.RandomForestClassifier(max_depth = b, min_samples_split=c, n_estimators = a, random_state = seed)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "acc24 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse24 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse24 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm24 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm24, annot=True, cmap=\"Greens\", cbar=False, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(svc,param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=10, gamma=1)\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "acc25 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse25 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse25 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm25 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm25, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "\n",
    "parameters = {'n_estimators' : [120, 150, 180],\n",
    "'learning_rate': [0.05, 0.01, 0.1],\n",
    "'max_depth': [5,6,7]}\n",
    "\n",
    "clf = GridSearchCV(xgb_model,\n",
    "parameters,\n",
    "n_jobs=-1,\n",
    "verbose=2,\n",
    "refit = \"accuracy_score\")\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "best_pars = clf.best_params_\n",
    "l_rate = best_pars['learning_rate']\n",
    "m_depth = best_pars['max_depth']\n",
    "n_estim = best_pars['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgbMod = XGBClassifier(max_depth = m_depth, n_estimators = n_estim, learning_rate = l_rate, random_state = seed)\n",
    "xgbMod.fit(X_train,y_train)\n",
    "y_pred = xgbMod.predict(X_test)\n",
    "acc26 = metrics.balanced_accuracy_score(y_pred,y_test)\n",
    "mse26 = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse26 = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cm26 = confusion_matrix(y_pred,y_test)\n",
    "sns.heatmap(cm26, annot=True, cmap=\"Greens\", cbar=False,xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2=pd.DataFrame(columns=['Algorithm','Accuracy','MSE'])\n",
    "names=['KNN','Random Forest','SVM','XGBoost']\n",
    "for x in range(0,len(names)):\n",
    "    results2.loc[x] = [names[x],vars()['acc' + str(x+23)], vars()['mse' + str(x+23)]]\n",
    "results2.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "results2.set_index('Algorithm', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
